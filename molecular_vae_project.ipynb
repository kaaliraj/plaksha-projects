{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-al0a4J4O-h"
   },
   "source": [
    "references : \n",
    "https://github.com/YunjaeChoi/vaemols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z0VHod3a4cT8",
    "outputId": "c0321f83-f1e6-4f50-d749-381c6d4ab597"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1TehohP-EHqQ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "02vZZtUNJLo6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "vUzP0HfgG3dG"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/content/drive/MyDrive/zinc-15.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "id": "okwQjdqlFC1R",
    "outputId": "5039bf23-6c39-4361-b1cc-e89b6e61a2c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zinc_id</th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZINC000000008151</td>\n",
       "      <td>C[C@H]1[C@@H](O)[C@H](CO)O[C@@H](O)[C@@H]1N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZINC000000008153</td>\n",
       "      <td>CC[C@@H]1[C@@H](N)[C@@H](O)O[C@@H](CO)[C@@H]1O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZINC000000008155</td>\n",
       "      <td>CC1(C)[C@@H](N)[C@@H](O)O[C@@H](CO)[C@@H]1O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZINC000000018276</td>\n",
       "      <td>CS[C@@H]1CN[C@@H](CO)[C@H](O)[C@H]1O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZINC000000018279</td>\n",
       "      <td>CS[C@@H]1[C@@H](O)CN[C@@H](CO)[C@@H]1O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427851</th>\n",
       "      <td>ZINC000242463989</td>\n",
       "      <td>O[Cl+3](O)(O)O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427852</th>\n",
       "      <td>ZINC000247713634</td>\n",
       "      <td>O1[SiH2][SiH2]O[SiH2][SiH2]1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427853</th>\n",
       "      <td>ZINC000252581626</td>\n",
       "      <td>O[Si](O)(O)F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427854</th>\n",
       "      <td>ZINC000685945533</td>\n",
       "      <td>Cn1nnnc1S(=O)(=O)F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427855</th>\n",
       "      <td>ZINC000725262634</td>\n",
       "      <td>Cn1nnc(S(=O)(=O)F)n1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427856 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 zinc_id                                          smiles\n",
       "0       ZINC000000008151     C[C@H]1[C@@H](O)[C@H](CO)O[C@@H](O)[C@@H]1N\n",
       "1       ZINC000000008153  CC[C@@H]1[C@@H](N)[C@@H](O)O[C@@H](CO)[C@@H]1O\n",
       "2       ZINC000000008155     CC1(C)[C@@H](N)[C@@H](O)O[C@@H](CO)[C@@H]1O\n",
       "3       ZINC000000018276            CS[C@@H]1CN[C@@H](CO)[C@H](O)[C@H]1O\n",
       "4       ZINC000000018279          CS[C@@H]1[C@@H](O)CN[C@@H](CO)[C@@H]1O\n",
       "...                  ...                                             ...\n",
       "427851  ZINC000242463989                                  O[Cl+3](O)(O)O\n",
       "427852  ZINC000247713634                    O1[SiH2][SiH2]O[SiH2][SiH2]1\n",
       "427853  ZINC000252581626                                    O[Si](O)(O)F\n",
       "427854  ZINC000685945533                              Cn1nnnc1S(=O)(=O)F\n",
       "427855  ZINC000725262634                            Cn1nnc(S(=O)(=O)F)n1\n",
       "\n",
       "[427856 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KARzJNMlaQHd"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DCqLaNZ0HtxZ",
    "outputId": "df642d42-ffbc-4a77-abed-6bd033e2be87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427856,)"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_data = data['smiles']\n",
    "smiles_data = np.array(smiles_data).reshape(-1)\n",
    "smiles_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SGeK_WUInrAP",
    "outputId": "d7b7ff8b-71b2-4282-bb81-1eb2c48f9291"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C[C@H]1[C@@H](O)[C@H](CO)O[C@@H](O)[C@@H]1N',\n",
       "       'CC[C@@H]1[C@@H](N)[C@@H](O)O[C@@H](CO)[C@@H]1O',\n",
       "       'CC1(C)[C@@H](N)[C@@H](O)O[C@@H](CO)[C@@H]1O', ..., 'O[Si](O)(O)F',\n",
       "       'Cn1nnnc1S(=O)(=O)F', 'Cn1nnc(S(=O)(=O)F)n1'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JEJWuVr_H4Mf",
    "outputId": "83162646-5dd0-460d-a903-a8b7af55eae5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mols: 427856\n",
      "Number of valid mols: 56767\n"
     ]
    }
   ],
   "source": [
    "print('Number of mols: '+str(len(smiles_data)))\n",
    "idx = [i for i, x in enumerate(smiles_data) if len(x)<=20]\n",
    "print('Number of valid mols: '+str(len(idx)))\n",
    "smiles_data = smiles_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R87Ne3HSIDXM",
    "outputId": "1c1ed36f-ddce-49e2-d781-791bb802b8c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56767/56767 [00:00<00:00, 426077.47it/s]\n"
     ]
    }
   ],
   "source": [
    "char_set = set()\n",
    "for i in tqdm(range(len(smiles_data))):\n",
    "    smiles_data[i] = smiles_data[i].ljust(20)\n",
    "    char_set = char_set.union(set(smiles_data[i]))\n",
    "char_set_list = sorted(list(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2PF26wLNJY6k"
   },
   "outputs": [],
   "source": [
    "char_to_int = dict((c, i) for i, c in enumerate(char_set))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0-GNJYWKwWv",
    "outputId": "b0ebd374-71fb-4122-d64a-c9ab95406e76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56767/56767 [00:00<00:00, 155016.90it/s]\n"
     ]
    }
   ],
   "source": [
    "labeled_data = np.zeros((len(smiles_data), 120, 1), dtype=np.int32)\n",
    "for i in tqdm(range(len(smiles_data))):\n",
    "    for t, char in enumerate(smiles_data[i]):\n",
    "        labeled_data[i, t, 0] = char_to_int[char]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4zb2SP4YlVT",
    "outputId": "498b629a-27be-4a48-c787-6da3230ae8bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56767"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smiles_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NuqJFQz5LBDi"
   },
   "outputs": [],
   "source": [
    "x_train, x_val_test = train_test_split(labeled_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_OF1MFppQWsR"
   },
   "outputs": [],
   "source": [
    "x_val = x_val_test[:len(x_val_test)//2]\n",
    "x_test = x_val_test[len(x_val_test)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8PXWuXYmR56v"
   },
   "outputs": [],
   "source": [
    "num_classes = len(char_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VNwbMQCpY0UV"
   },
   "outputs": [],
   "source": [
    "class VAEDataGenerator(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, x, num_classes, batch_size=32):\n",
    "        self.x = x\n",
    "        self.num_classes = num_classes\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x_one_hot = tf.keras.utils.to_categorical(batch_x, num_classes=self.num_classes)\n",
    "        return (batch_x_one_hot, batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tmvBaLTQWUgU"
   },
   "outputs": [],
   "source": [
    "x_train_gen = VAEDataGenerator(x_train, num_classes, batch_size=32)\n",
    "x_val_gen = VAEDataGenerator(x_val, num_classes, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "QNe34cdfbnSi"
   },
   "outputs": [],
   "source": [
    "class EncoderConv1D(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim, num_samples=16, name='encoder_conv1d'):\n",
    "        super(EncoderConv1D, self).__init__(name=name)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv1D(filters=32, kernel_size=7, strides=3)\n",
    "        self.norm1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act1 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv1D(filters=64, kernel_size=7, strides=3)\n",
    "        self.norm2 = tf.keras.layers.BatchNormalization()\n",
    "        self.act2 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.conv3 = tf.keras.layers.Conv1D(filters=128, kernel_size=7, strides=3)\n",
    "        self.norm3 = tf.keras.layers.BatchNormalization()\n",
    "        self.act3 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(512)\n",
    "        self.dense_norm1 = tf.keras.layers.BatchNormalization()\n",
    "        self.dense_act1 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.z_mean_dense = tf.keras.layers.Dense(self.latent_dim)\n",
    "        self.z_log_var_dense = tf.keras.layers.Dense(self.latent_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        with tf.compat.v1.variable_scope(self.name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "            x = self.conv1(inputs)\n",
    "            x = self.norm1(x)\n",
    "            x = self.act1(x)\n",
    "\n",
    "            x = self.conv2(x)\n",
    "            x = self.norm2(x)\n",
    "            x = self.act2(x)\n",
    "\n",
    "            x = self.conv3(x)\n",
    "            x = self.norm3(x)\n",
    "            x = self.act3(x)\n",
    "            x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "            z_mean = self.z_mean_dense(x)\n",
    "            z_log_var = self.z_log_var_dense(x)\n",
    "\n",
    "            self.dist = tf.compat.v1.distributions.Normal(loc=z_mean, scale=tf.exp(0.5*z_log_var))\n",
    "            sampled = self.dist.sample(self.num_samples)\n",
    "            z = tf.transpose(sampled, [1, 0, 2])\n",
    "            return z, z_mean, z_log_var\n",
    "\n",
    "class Decoderlstm(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, charset_length, max_length, name='decoder_lstm'):\n",
    "        super(Decoderlstm, self).__init__(name=name)\n",
    "        self.charset_length = charset_length\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(512)\n",
    "        self.norm1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act1 = tf.keras.layers.Activation('relu')\n",
    "        self.repeat = tf.keras.layers.RepeatVector(self.max_length)\n",
    "\n",
    "        self.lstm1 = tf.compat.v1.keras.layers.LSTM(512, return_sequences=True)\n",
    "        self.norm2 = tf.keras.layers.BatchNormalization()\n",
    "        self.lstm2 = tf.compat.v1.keras.layers.LSTM(512, return_sequences=True)\n",
    "        self.norm3 = tf.keras.layers.BatchNormalization()\n",
    "        self.lstm3 = tf.compat.v1.keras.layers.LSTM(512, return_sequences=True)\n",
    "        self.out_dense = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(self.charset_length))\n",
    "        self.out_act = tf.keras.layers.Activation('softmax')\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        with tf.compat.v1.variable_scope(self.name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "            x = self.dense1(inputs)\n",
    "            x = self.norm1(x)\n",
    "            x = self.act1(x)\n",
    "\n",
    "            x = self.repeat(x)\n",
    "            x = self.lstm1(x)\n",
    "            x = self.norm2(x)\n",
    "            x = self.lstm2(x)\n",
    "            x = self.norm3(x)\n",
    "            x = self.lstm3(x)\n",
    "            outputs_logits = self.out_dense(x)\n",
    "            outputs = self.out_act(outputs_logits)\n",
    "            return outputs, outputs_logits\n",
    "\n",
    "class VariationalAutoencoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, latent_dim, charset_length, max_length, num_samples=16, name='vae'):\n",
    "        super(VariationalAutoencoder, self).__init__(name=name)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.charset_length = charset_length\n",
    "        self.max_length = max_length\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "        self.encoder = EncoderConv1D(self.latent_dim, num_samples=self.num_samples)\n",
    "        self.decoder = Decoderlstm(charset_length, max_length)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        with tf.compat.v1.variable_scope(self.name, reuse=tf.compat.v1.AUTO_REUSE):\n",
    "            z, self.z_mean, self.z_log_var = self.encoder(inputs)\n",
    "            z_reshaped = tf.reshape(z, (-1, self.encoder.latent_dim))\n",
    "            outputs, self.outputs_logits = self.decoder(z_reshaped)\n",
    "            return outputs\n",
    "\n",
    "    def vae_loss_func(self, y_true, y_pred):\n",
    "        latent_loss = -0.5*tf.reduce_sum(1.0 + self.z_log_var - tf.square(self.z_mean) - tf.exp(self.z_log_var), 1)\n",
    "        y_true_r = tf.reshape(y_true, [-1, 1, self.max_length])\n",
    "        y_true_c = tf.cast(y_true_r, tf.int64)\n",
    "        tiled = tf.tile(y_true_c, (1, self.num_samples, 1))\n",
    "        y_true_rep = tf.reshape(tiled, (-1, self.max_length))\n",
    "        recon_loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(y_true_rep, self.outputs_logits, reduction=tf.compat.v1.losses.Reduction.SUM)\n",
    "        recon_loss = recon_loss/tf.cast(self.num_samples, tf.float32)\n",
    "        vae_loss = latent_loss + recon_loss\n",
    "        return vae_loss\n",
    "\n",
    "    def sampled_data_acc(self, y_true, y_pred):\n",
    "        y_true_r = tf.reshape(y_true, [-1, 1, self.max_length])\n",
    "        y_true_c = tf.cast(y_true_r, tf.int64)\n",
    "        tiled = tf.tile(y_true_c, (1, self.num_samples, 1))\n",
    "        y_true_rep = tf.reshape(tiled, (-1, self.max_length))\n",
    "        y_pred_class = tf.argmax(y_pred, axis=-1)\n",
    "        acc = tf.reduce_mean(tf.cast(tf.equal(y_true_rep, y_pred_class), tf.float32))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wA6SxJ-fZUux",
    "outputId": "6ff8cb02-1b36-4ee4-da49-b4d906e777dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-92a1a1282b07>:45: Normal.__init__ (from tensorflow.python.ops.distributions.normal) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/normal.py:160: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "inputs = tf.keras.layers.Input(shape=(120, num_classes))\n",
    "vae = VariationalAutoencoder(256, num_classes, 120, num_samples=4)\n",
    "outputs = vae(inputs)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.0003, clipvalue=0.1)\n",
    "vae.compile(optimizer=optimizer, loss=vae.vae_loss_func, metrics=[vae.sampled_data_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ncj0qHPQfjAL"
   },
   "outputs": [],
   "source": [
    "#callbacks\n",
    "ckpt = tf.keras.callbacks.ModelCheckpoint('saved_models/' + 'weights-{epoch:02d}-{val_loss:.4f}.ckpt',\n",
    "                                              monitor='val_loss',\n",
    "                                              verbose=1, save_best_only=True,\n",
    "                                              mode='auto', save_weights_only=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, min_lr=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZHRBhVPfjbi",
    "outputId": "c9ee4887-7feb-4def-d421-bec99e0d2b83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1419/1420 [============================>.] - ETA: 1s - loss: 511.2832 - sampled_data_acc: 0.9598WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1420/1420 [==============================] - ETA: 0s - loss: 511.2481 - sampled_data_acc: 0.9599WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "1420/1420 [==============================] - 2174s 2s/step - loss: 511.2481 - sampled_data_acc: 0.9599 - val_loss: 421.3514 - val_sampled_data_acc: 0.9692\n",
      "\n",
      "Epoch 00001: val_loss improved from 609.04718 to 421.35138, saving model to saved_models/weights-01-421.3514.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f75629d2240>"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.fit_generator(epochs=1, generator=x_train_gen, validation_data=x_val_gen,\n",
    "                      use_multiprocessing=True, workers=4,\n",
    "                      callbacks=[ckpt, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8MiFKTfz47s"
   },
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "inputs = tf.keras.layers.Input(shape=(120, num_classes))\n",
    "vae = VariationalAutoencoder(latent_dim, num_classes, 120, num_samples=1)\n",
    "outputs = vae(inputs)\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(latent_dim,))\n",
    "decoder_outputs = vae.decoder(decoder_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "C9gD3bHZ412_"
   },
   "outputs": [],
   "source": [
    "input_data = tf.keras.utils.to_categorical(labeled_data[:1], num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L66aZogK5Sg_",
    "outputId": "7e67cb62-3db8-4f53-a843-30df2ba9604b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMii-SOz5UYA",
    "outputId": "a4d41a5a-3864-4338-a23f-4e82fd43fbfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vae.encoder.predict(input_data)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SUCGQgHS6qBC"
   },
   "outputs": [],
   "source": [
    "restore_model_dir = 'saved_models/'\n",
    "restore_model_path = tf.train.latest_checkpoint(restore_model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Z7gRAH3hJ_5H"
   },
   "outputs": [],
   "source": [
    "z_mean = vae.encoder.predict(input_data)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "OLbosExJKDXi"
   },
   "outputs": [],
   "source": [
    "num_samples = 4\n",
    "std = 0.4\n",
    "z_mean = np.tile(z_mean, (num_samples, 1))\n",
    "z_samples = np.random.normal(loc=z_mean, scale=std, size=z_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "8AmYyT8AKy1O"
   },
   "outputs": [],
   "source": [
    "outputs = vae.decoder.predict(z_samples)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "x4pCoR5JLmCw"
   },
   "outputs": [],
   "source": [
    "def smiles_to_labels(smiles_data, char_to_int, max_length):\n",
    "    labeled_data = np.zeros((len(smiles_data), max_length, 1), dtype=np.int32)\n",
    "    smiles_data = [d.ljust(max_length) for d in smiles_data]\n",
    "    for i in range(len(smiles_data)):\n",
    "        for t, char in enumerate(smiles_data[i]):\n",
    "            labeled_data[i, t, 0] = char_to_int[char]\n",
    "    return labeled_data\n",
    "\n",
    "def labels_to_smiles(labeled_data, int_to_char):\n",
    "    return np.array([''.join([int_to_char[label] for label in labels]).strip(' ')\n",
    "                     for labels in labeled_data], dtype=np.str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "yK1lvWsgS8cb"
   },
   "outputs": [],
   "source": [
    "output_labels = np.argmax(outputs, axis=-1)\n",
    "smiles = labels_to_smiles(output_labels, int_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqzcZ_BOTyZt",
    "outputId": "57331ed5-abc2-4eea-8390-c9acb4923a80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CCCC111cc](O)ccc)nn1OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO',\n",
       "       'CCCc1cccc(())cc(N)n1OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO',\n",
       "       'CCCc11nnc((O)ccc)nn1OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO',\n",
       "       'CCCc11nnc((O)ccN)nn1OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO'],\n",
       "      dtype='<U120')"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "molecular vae project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
